import spacy
from heapq import nlargest

nlp = spacy.load("en_core_web_sm")

def extractive_summary(text, num_sents=3):
    doc = nlp(text)
    sentence_scores = {}
    for sent in doc.sents:
        for token in sent:
            if token.is_stop or token.is_punct:
                continue
            sentence_scores[sent] = sentence_scores.get(sent, 0) + 1
    top_sents = nlargest(num_sents, sentence_scores, key=sentence_scores.get)
    return ' '.join([sent.text for sent in top_sents])

# Use example
if __name__ == "__main__":
    article = "This is the first sentence. This is the second sentence. This is the third sentence. This is the fourth sentence."
    print("Extractive Summary:")
    print(extractive_summary(article))
